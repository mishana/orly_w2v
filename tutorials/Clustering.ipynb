{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [K-Means](#k_means)\n",
    "    * [Minibatch](#minibatch_k_means)\n",
    "    * [Finding the optimal number of clusters](#optimal_num_clusters)\n",
    "* [Hierarchical Clustering](#hierarchical_clustering)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# inline plot \n",
    "%matplotlib inline  \n",
    "# default figure size \n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "# to make our sets reproducible \n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, y=None):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    \n",
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=35, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=2, linewidths=12,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    # take some margines so we can visualize all points\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    \n",
    "    # define a gird over the domain\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    \n",
    "    # predict clusters of the grid \n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # print the clustering boundaries and fill the regions with deifferent colors\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    \n",
    "    # plot the data \n",
    "    plot_data(X)\n",
    "    \n",
    "    # plot the centroids of the clusters\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "    # axis labels\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "        \n",
    "def plot_clusterer_comparison(clusterer1, clusterer2, X, title1=None, title2=None):\n",
    "    clusterer1.fit(X)\n",
    "    clusterer2.fit(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 3.2))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plot_decision_boundaries(clusterer1, X)\n",
    "    if title1:\n",
    "        plt.title(title1, fontsize=14)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plot_decision_boundaries(clusterer2, X, show_ylabels=False)\n",
    "    if title2:\n",
    "        plt.title(title2, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Blobs data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "# Generate isotropic Gaussian blobs for clustering.\n",
    " \n",
    "# centers \n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "# standard deviations \n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "\n",
    "# generate\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_clusters(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means <a class=\"anchor\" id=\"k_means\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# number of clusters \n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "# bath refer to the same object\n",
    "print(f'The assigned labels : {kmeans.labels_} which is the same as y_pred')\n",
    "print(f'First three points labels {y_pred[:3]}')\n",
    "\n",
    "print(f'The {len(kmeans.cluster_centers_)} centroids')\n",
    "print('\\n'.join([f'group {idx} centroid: {c}' for idx, c in enumerate(kmeans.cluster_centers_)]))\n",
    "print(f'objective (cost) : {kmeans.inertia_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign new samples to clusters\n",
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the decision boundharies\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state is set to 0 so the same initial points will be used\n",
    "\n",
    "def get_kmeans_stages(stages: int = 3, init_centroids = None):\n",
    "    \n",
    "    if init_centroids is None:\n",
    "        init_centroids = \"random\"\n",
    "    for k in range(stages):\n",
    "        kmeans_iter = KMeans(n_clusters=5, init=init_centroids, n_init=1,\n",
    "                             algorithm=\"full\", max_iter=k + 1, random_state=0)\n",
    "        kmeans_iter.fit(X)\n",
    "\n",
    "        yield kmeans_iter\n",
    "\n",
    "first_stage = None\n",
    "def plot_stages(X, stages: int = 3, init_centroids = None):\n",
    "    \n",
    "    plt.figure(figsize=(10, 20))\n",
    "\n",
    "    # PLOT THE DATA WITH INITIAL CENTROIDS \n",
    "    plt.subplot(stages, 2, 1)\n",
    "    plot_data(X)\n",
    "    kmeans_stages = get_kmeans_stages(stages, init_centroids=init_centroids)\n",
    "    first_stage = next(kmeans_stages)\n",
    "    \n",
    "    # CALCULATE CENTROIDS \n",
    "    plot_centroids(first_stage.cluster_centers_, circle_color='r', cross_color='w')\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.title(\"Update the centroids (initially randomly)\", fontsize=14)\n",
    "    \n",
    "    # PLOT THE FIRST LABELS ASSIGNMENT\n",
    "    plt.subplot(stages, 2, 2)\n",
    "    plot_decision_boundaries(first_stage, X, show_xlabels=False, show_ylabels=False)\n",
    "    plt.title(\"Label the instances\", fontsize=14)\n",
    "    \n",
    "    prev_stage = first_stage\n",
    "    for idx, next_stage in enumerate(kmeans_stages):\n",
    "        \n",
    "         # PLOT THE NEW LABELS ASSIGNMENT BASED ON PREVIOUS STAGE CENTROIDS \n",
    "        plt.subplot(stages, 2, 2 * (idx + 1) + 1)\n",
    "        plot_decision_boundaries(prev_stage, X, show_centroids=False, show_xlabels=False)\n",
    "        plot_centroids(next_stage.cluster_centers_)\n",
    "        \n",
    "        # CALCULATE NEW CENTROIDS\n",
    "        plt.subplot(stages, 2, 2 * (idx + 1) + 2)\n",
    "        plot_decision_boundaries(next_stage, X, show_xlabels=False, show_ylabels=False)\n",
    "        \n",
    "        # update previous stage\n",
    "        prev_stage = next_stage\n",
    "        \n",
    "first_stage = plot_stages(X, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch K-Means <a class=\"anchor\" id=\"minibatch_k_means\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=5, random_state=42)\n",
    "minibatch_kmeans.fit(X)\n",
    "\n",
    "# The inertia is defined as the sum of square distances of samples to their nearest neighbor.\n",
    "minibatch_kmeans.inertia_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mnist[\"data\"], mnist[\"target\"], random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using memory map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_mnist.data\"\n",
    "X_mm = np.memmap(filename, dtype='float32', mode='write', shape=X_train.shape)\n",
    "X_mm[:] = X_train\n",
    "\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=10, batch_size=10, random_state=42)\n",
    "minibatch_kmeans.fit(X_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom minibatch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model by feeding it one batch at a time. \n",
    "# implements multiple initializations and keep the model with the lowest inertia\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def load_next_batch(batch_size):\n",
    "    return X[np.random.choice(len(X), batch_size, replace=False)]\n",
    "\n",
    "# number of clusters\n",
    "k = 5\n",
    "# number of initializations \n",
    "n_init = 10\n",
    "# number of iterations per init\n",
    "n_iterations = 100\n",
    "# batch size \n",
    "batch_size = 100\n",
    "# use more data in first iteration\n",
    "init_size = 500  \n",
    "\n",
    "# evaluate on last evaluate_on_last_n_iters batches\n",
    "# note that first batches don't tell us much\n",
    "evaluate_on_last_n_iters = 10\n",
    "\n",
    "best_kmeans = None\n",
    "\n",
    "for init in range(n_init):\n",
    "    # initialize the model\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=k, init_size=init_size)\n",
    "    # get the first batch and fit\n",
    "    X_init = load_next_batch(init_size)\n",
    "    minibatch_kmeans.partial_fit(X_init)\n",
    "    # create a new attribute named sum_inertia_ and initialize it to zero\n",
    "    minibatch_kmeans.sum_inertia_ = 0\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        # get the next batch and fit\n",
    "        X_batch = load_next_batch(batch_size)\n",
    "        minibatch_kmeans.partial_fit(X_batch)\n",
    "        # will enter in the last evaluate_on_last_n_iters iterations\n",
    "        if iteration >= n_iterations - evaluate_on_last_n_iters:\n",
    "            minibatch_kmeans.sum_inertia_ += minibatch_kmeans.inertia_\n",
    "\n",
    "    if (best_kmeans is None or minibatch_kmeans.sum_inertia_ < best_kmeans.sum_inertia_):\n",
    "        best_kmeans = minibatch_kmeans\n",
    "        \n",
    "# Opposite of the value of X on the K-means objective.\n",
    "best_kmeans.score(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Optimal Number of Clusters <a class=\"anchor\" id=\"optimal_num_clusters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model per numbber of clusters setting\n",
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X) for k in range(1, 10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.annotate('Elbow',\n",
    "             xy=(4, inertias[3]),\n",
    "             xytext=(0.55, 0.55),\n",
    "             textcoords='figure fraction',\n",
    "             fontsize=16,\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.axis([1, 8.5, 0, 1300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_scores = [silhouette_score(X, model.labels_) for model in kmeans_per_k[1:]]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.axis([1.8, 8.5, 0.55, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (3, 4, 5, 6):\n",
    "    plt.subplot(2, 2, k - 2)\n",
    "    \n",
    "    y_pred = kmeans_per_k[k - 1].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X, y_pred)\n",
    "\n",
    "    padding = len(X) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = matplotlib.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (3, 5):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "    \n",
    "    if k in (5, 6):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(\"$k={}$\".format(k), fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering <a class=\"anchor\" id=\"hierarchical_clustering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "variables = ['X', 'Y', 'Z']\n",
    "labels = ['ID_0','ID_1','ID_2','ID_3','ID_4']\n",
    "X = np.random.random_sample([5,3])*10\n",
    "df = pd.DataFrame(X, columns=variables, index=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# squareform - condensed distance matrix is passed, a redundant one is returned\n",
    "# pdist - Pairwise distances between observations in n-dimensional space.\n",
    "row_dist = pd.DataFrame(squareform(\n",
    "    pdist(df, metric='euclidean')),\n",
    "    columns=labels, index=labels)\n",
    "row_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will apply the complete linkage agglomeration to our clusters using the\n",
    "# linkage function from SciPy's cluster.hierarchy submodule, which returns a\n",
    "# so-called linkage matrix.\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "# row_clusters = linkage(pdist(df, metric='euclidean'), method='complete')\n",
    "row_clusters = linkage(df.values, metric='euclidean', method='complete')\n",
    "\n",
    "# each row represents one merge \n",
    "# The first and second columns denote the most\n",
    "# dissimilar members in each cluster, and the third column reports the distance between\n",
    "# those members. The last column returns the count of the members in each cluster\n",
    "df = pd.DataFrame(\n",
    "    row_clusters,\n",
    "    columns=['row label 1',\n",
    "              'row label 2',\n",
    "              'distance',\n",
    "              'no. of items in clust.'],\n",
    "    index=['cluster %d' %(i+1) for i in range(row_clusters.shape[0])]\n",
    ")\n",
    "df['row label 1'] = df['row label 1'].astype(int)\n",
    "df['row label 2'] = df['row label 2'].astype(int)\n",
    "df['no. of items in clust.'] = df['no. of items in clust.'].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have computed the linkage matrix, we can visualize the results in the\n",
    "# form of a dendrogram:\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "row_dendr = dendrogram(row_clusters,\n",
    "    labels=labels)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Euclidean distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ac = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='complete')\n",
    "labels = ac.fit_predict(X)\n",
    "print('Cluster labels: %s' % labels)\n",
    "# stopped when reached 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "labels = ac.fit_predict(X)\n",
    "print('Cluster labels: %s' % labels)\n",
    "# proceeded to merge ID_3 with ID_0 and ID_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "thresh = 3.8\n",
    "# As we see there are exactly 3 clusters when limmiting the distance to 3.8\n",
    "model = AgglomerativeClustering(distance_threshold=thresh, linkage='complete', n_clusters=None)\n",
    "\n",
    "model = model.fit(X)\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top 7 levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode='level', p=7)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.axhline(y=thresh, color='r', linestyle='-')\n",
    "\n",
    "print(f'Num clusters: {model.n_clusters_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}