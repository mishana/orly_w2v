{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Final Assignment - Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "WINDOW_SIZE = 4\n",
    "NUM_NS = 4\n",
    "EMBEDDING_DIM = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "file_path = \"reviews_data.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the first few lines:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oct nice trendy hotel location not too bad stayed in this hotel for one night as this is fairly new place some of the taxi drivers did not know where it was and or did not want to drive there once have eventually arrived at the hotel was very pleasantly surprised with the decor of the lobby ground floor area it was very stylish and modern found the reception staff geeting me with aloha bit out of place but guess they are briefed to say that to keep up the coroporate image as have starwood preferred guest member was given small gift upon check in it was only couple of fridge magnets in gift box but nevertheless nice gesture my room was nice and roomy there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by bliss the location is not great it is at the last metro stop and you then need to take taxi but if you are not planning on going to see the historic sites in beijing then you will be ok chose to have some breakfast in the hotel which was really tasty and there was good selection of dishes there are couple of computers to use in the communal area as well as pool table there is also small swimming pool and gym area would definitely stay in this hotel again but only if did not plan to travel to central beijing as it can take long time the location is ok if you plan to do lot of shopping as there is big shopping centre just few minutes away from the hotel and there are plenty of eating options around including restaurants that serve dog meat\n",
      "sep great budget hotel stayed two nights at aloft on the most recent trip to china the hotel was very modern and clean the room was spotless and comfortable king sized bed as far as soft beds go in china the staff was very punctual and went out of the way to help my every need including going to store across the street to purchase china mobile sim card for me the buffet breakfast was okay nothing to write home about the lcd screen had movies on demand for rmb and had good selection of western channels including hbo cnn bbc star world etc the gym was small had selection of basic weights and one cable machine there was however new technogym cardio machines with built in lcd tvs which were very good the location is bit out of the way to the central areas of beijing but it is better suited for my needs as need to be in the haidian district being spg platinum there were no upgrades to better room because aloft has policy of not doing any upgrades the sheraton next door is much nicer hotel in my opinion where am writing this from now with an upgraded room but as far as bang for the buck aloft is great place\n",
      "aug excellent value location not big problem we stayed at the aloft beijing haidian for nights from july nd there are lots of reviews that talk about the location being problem but we knew this ahead of time and found that it really wasn an issue the longest we spent in taxi was about minutes we never paid more than rmb for taxi ride which is about cdn and that was to the forbidden city given there are in our family it was no big deal at all as for the rooms they were clean the beds comfortable the wireless internet connection reliable and it was one of the few hotels we found in beijing that would accomodate adults and children we paid about cdn per night that an amazing price it not meant to be star hotel so you can go in expecting that we found the reception staff generally very helpful and friendly they aren the fastest in the world but it wasn unreasonable at all the hotel manager made an effort to speak with us few times and was extremely helpful and welcoming their breakfast buffet was quite good and reasonably priced there are number of good restaurants in the four points sheraton next door so there were lots of options there is massive mall about block away that has other dining options as well the only issue we ran into was few taxi drivers refusing to take us to the summer palace because guess they felt it wasn far enough the minimum rate is rmb but the staff at the four points sheraton which is on busier road than the side street for aloft were quite helpful in finding taxis for us if they weren already there we would definitely stay there again and recommend it to our friends for its excellent value\n"
     ]
    }
   ],
   "source": [
    "for line in lines[:3]:\n",
    "    print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, it seems like the reviews data is already all lower case and with no punctuation.\n",
    "Let us find the vocabulary size first, and determine which words we want to subsample:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "seq_lengths = []\n",
    "\n",
    "from collections import defaultdict\n",
    "word_frequencies = defaultdict(int)\n",
    "\n",
    "for line in lines:\n",
    "    words = line.split()\n",
    "    seq_lengths.append(len(words))\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "        word_frequencies[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "[('the', 2812098),\n ('and', 1472767),\n ('to', 1077721),\n ('was', 903010),\n ('in', 748274),\n ('we', 660041),\n ('of', 614458),\n ('hotel', 565672),\n ('for', 544389),\n ('is', 528043),\n ('it', 509630),\n ('room', 445320),\n ('at', 361647),\n ('but', 349456),\n ('on', 335747),\n ('you', 335174),\n ('were', 330943),\n ('with', 320517),\n ('that', 310995),\n ('very', 307420),\n ('this', 307138),\n ('not', 283312),\n ('had', 260005),\n ('there', 241531),\n ('our', 225339),\n ('are', 211395),\n ('as', 210432),\n ('great', 209799),\n ('have', 207932),\n ('my', 204468),\n ('from', 203631),\n ('stay', 189007),\n ('they', 183122),\n ('good', 169934),\n ('all', 169433),\n ('so', 169008),\n ('be', 168374),\n ('staff', 161593),\n ('would', 157965),\n ('location', 154375),\n ('if', 146917),\n ('rooms', 138413),\n ('one', 137352),\n ('which', 127852),\n ('nice', 122123),\n ('no', 120443),\n ('stayed', 119642),\n ('out', 115511),\n ('us', 111793),\n ('clean', 111578),\n ('an', 110669),\n ('night', 110545),\n ('just', 110285),\n ('quot', 109413),\n ('breakfast', 108911),\n ('when', 107827),\n ('only', 105186),\n ('or', 100393),\n ('about', 99428),\n ('service', 98602),\n ('get', 98324),\n ('up', 91845),\n ('time', 88466),\n ('also', 87489),\n ('can', 85178),\n ('by', 84980),\n ('small', 81930),\n ('here', 78708),\n ('again', 77184),\n ('place', 75225),\n ('bed', 74126),\n ('day', 73834),\n ('like', 73816),\n ('well', 73455),\n ('could', 73011),\n ('other', 72650),\n ('me', 72510),\n ('some', 71552),\n ('did', 71100),\n ('really', 70641),\n ('bathroom', 69942),\n ('more', 69872),\n ('friendly', 66564),\n ('your', 64522),\n ('will', 64380),\n ('back', 64222),\n ('what', 64065),\n ('than', 64025),\n ('floor', 63971),\n ('after', 63398),\n ('london', 63315),\n ('two', 61864),\n ('walk', 61861),\n ('even', 60508),\n ('comfortable', 60402),\n ('area', 60235),\n ('go', 58776),\n ('excellent', 57466),\n ('check', 56449),\n ('hotels', 56408),\n ('helpful', 55973),\n ('price', 55772),\n ('got', 55279),\n ('been', 54325),\n ('desk', 54032),\n ('much', 53912),\n ('street', 53809),\n ('do', 53546),\n ('little', 52133),\n ('first', 51485),\n ('new', 50996),\n ('didn', 50917),\n ('has', 49424),\n ('next', 49157),\n ('around', 48862),\n ('nights', 48750),\n ('free', 47433),\n ('front', 47315),\n ('food', 47256),\n ('too', 46991),\n ('booked', 45621),\n ('their', 44711),\n ('down', 44225),\n ('best', 43682),\n ('city', 43437),\n ('any', 43348),\n ('right', 43322),\n ('view', 43124),\n ('away', 43101),\n ('people', 43047),\n ('recommend', 42999),\n ('th', 42762),\n ('restaurant', 42540),\n ('because', 41955),\n ('bar', 41896),\n ('over', 41298),\n ('shower', 40458),\n ('bit', 40269),\n ('don', 40049),\n ('found', 39596),\n ('most', 39523),\n ('large', 39233),\n ('them', 39170),\n ('better', 38745),\n ('then', 38242),\n ('who', 38242),\n ('amp', 37846),\n ('off', 37771),\n ('close', 37509),\n ('its', 37295),\n ('quite', 37254),\n ('times', 37183),\n ('pool', 37065),\n ('am', 36785),\n ('may', 36758),\n ('never', 36571),\n ('station', 36432),\n ('trip', 35870),\n ('want', 35859),\n ('however', 35715),\n ('few', 35664),\n ('value', 35629),\n ('everything', 35477),\n ('door', 35263),\n ('way', 35083),\n ('many', 35050),\n ('minutes', 34990),\n ('where', 34582),\n ('lobby', 34496),\n ('before', 34303),\n ('went', 34152),\n ('beds', 34132),\n ('made', 33978),\n ('restaurants', 33905),\n ('though', 33593),\n ('morning', 33416),\n ('square', 33290),\n ('every', 33214),\n ('experience', 32984),\n ('coffee', 32785),\n ('find', 32772),\n ('old', 32654),\n ('big', 32409),\n ('see', 32086),\n ('park', 31969),\n ('he', 31934),\n ('tv', 31274),\n ('into', 31017),\n ('reviews', 30636),\n ('being', 30568),\n ('quiet', 30539),\n ('water', 30528),\n ('staying', 30526),\n ('definitely', 30340),\n ('use', 30297),\n ('walking', 30100),\n ('enough', 30059),\n ('although', 29946),\n ('take', 29934),\n ('etc', 29726),\n ('told', 29556),\n ('oct', 29535),\n ('arrived', 29495),\n ('money', 29231),\n ('say', 29004),\n ('internet', 28846),\n ('always', 28598),\n ('perfect', 28477),\n ('going', 28441),\n ('noise', 28374),\n ('size', 28257),\n ('through', 28233),\n ('another', 28106),\n ('wonderful', 28083),\n ('need', 28069),\n ('overall', 28006),\n ('suite', 27838),\n ('aug', 27731),\n ('reception', 27609),\n ('make', 27540),\n ('think', 27417),\n ('asked', 27310),\n ('problem', 26794),\n ('bad', 26770),\n ('business', 26615),\n ('said', 26364),\n ('while', 26198),\n ('jul', 25902),\n ('lovely', 25664),\n ('fantastic', 25590),\n ('located', 25543),\n ('strip', 25509),\n ('rate', 25454),\n ('still', 25261),\n ('days', 25254),\n ('tube', 24855),\n ('sep', 24560),\n ('central', 24419),\n ('took', 24394),\n ('parking', 23992),\n ('loved', 23967),\n ('nov', 23812),\n ('long', 23804),\n ('ever', 23632),\n ('lot', 23596),\n ('hot', 23511),\n ('during', 23425),\n ('star', 23371),\n ('ve', 23323),\n ('looking', 23051),\n ('easy', 22752),\n ('car', 22698),\n ('vegas', 22633),\n ('ok', 22593),\n ('same', 22511),\n ('within', 22511),\n ('both', 22315),\n ('york', 22285),\n ('fine', 22247),\n ('last', 22114),\n ('thing', 22099),\n ('outside', 22082),\n ('left', 22036),\n ('weekend', 21974),\n ('each', 21931),\n ('full', 21897),\n ('pay', 21853),\n ('jun', 21822),\n ('side', 21798),\n ('expensive', 21622),\n ('building', 21614),\n ('across', 21570),\n ('shopping', 21508),\n ('nothing', 21462),\n ('high', 21460),\n ('sure', 21432),\n ('spacious', 21353),\n ('work', 21161),\n ('wasn', 21120),\n ('re', 21116),\n ('double', 21058),\n ('know', 21008),\n ('pretty', 20954),\n ('feel', 20889),\n ('she', 20888),\n ('top', 20798),\n ('st', 20788),\n ('having', 20764),\n ('how', 20704),\n ('paid', 20693),\n ('nyc', 20515),\n ('available', 20365),\n ('worth', 20302),\n ('extremely', 20204),\n ('early', 20099),\n ('wanted', 20056),\n ('huge', 20031),\n ('visit', 20007),\n ('apr', 19961),\n ('near', 19960),\n ('used', 19871),\n ('minute', 19779),\n ('per', 19759),\n ('since', 19646),\n ('checked', 19588),\n ('distance', 19520),\n ('deal', 19335),\n ('end', 19322),\n ('modern', 19172),\n ('called', 19141),\n ('far', 19078),\n ('beautiful', 18987),\n ('access', 18966),\n ('pleasant', 18860),\n ('things', 18714),\n ('concierge', 18698),\n ('three', 18667),\n ('given', 18577),\n ('came', 18562),\n ('should', 18534),\n ('blocks', 18446),\n ('mar', 18430),\n ('open', 18429),\n ('extra', 18351),\n ('felt', 18311),\n ('buffet', 18214),\n ('husband', 17997),\n ('come', 17980),\n ('choice', 17973),\n ('jan', 17850),\n ('sleep', 17801),\n ('air', 17788),\n ('couple', 17757),\n ('pm', 17660),\n ('thought', 17575),\n ('short', 17553),\n ('family', 17491),\n ('enjoyed', 17365),\n ('safe', 17362),\n ('without', 17313),\n ('looked', 17284),\n ('especially', 17280),\n ('guests', 17264),\n ('eat', 17230),\n ('subway', 17226),\n ('expect', 17123),\n ('standard', 17108),\n ('week', 17098),\n ('return', 17064),\n ('try', 17037),\n ('look', 17005),\n ('included', 16995),\n ('lots', 16722),\n ('towels', 16718),\n ('window', 16714),\n ('needed', 16706),\n ('corner', 16703),\n ('tea', 16681),\n ('evening', 16582),\n ('cheap', 16554),\n ('montreal', 16457),\n ('airport', 16447),\n ('amazing', 16435),\n ('home', 16432),\n ('late', 16352),\n ('plenty', 16312),\n ('convenient', 16288),\n ('bus', 16207),\n ('hour', 16156),\n ('able', 16027),\n ('put', 16003),\n ('places', 15989),\n ('hours', 15983),\n ('part', 15962),\n ('block', 15960),\n ('year', 15957),\n ('seemed', 15956),\n ('something', 15938),\n ('king', 15919),\n ('ask', 15903),\n ('once', 15829),\n ('several', 15727),\n ('quality', 15661),\n ('inn', 15595),\n ('feb', 15556),\n ('line', 15544),\n ('wait', 15511),\n ('road', 15409),\n ('getting', 15392),\n ('until', 15326),\n ('four', 15325),\n ('second', 15253),\n ('anything', 15212),\n ('space', 15106),\n ('bath', 15057),\n ('such', 14936),\n ('dinner', 14913),\n ('couldn', 14850),\n ('taxi', 14771),\n ('bedroom', 14732),\n ('charge', 14726),\n ('else', 14671),\n ('actually', 14650),\n ('main', 14623),\n ('probably', 14616),\n ('less', 14613),\n ('san', 14608),\n ('club', 14576),\n ('book', 14571),\n ('happy', 14555),\n ('highly', 14482),\n ('now', 14443),\n ('plus', 14352),\n ('call', 14288),\n ('itself', 14170),\n ('spent', 14093),\n ('different', 14089),\n ('anyone', 13983),\n ('manager', 13955),\n ('help', 13886),\n ('chicago', 13874),\n ('give', 13868),\n ('decent', 13804),\n ('dec', 13757),\n ('these', 13709),\n ('those', 13626),\n ('gave', 13613),\n ('travel', 13589),\n ('casino', 13419),\n ('problems', 13410),\n ('noisy', 13405),\n ('hard', 13392),\n ('cost', 13307),\n ('downtown', 13200),\n ('wife', 13199),\n ('must', 13111),\n ('luggage', 13090),\n ('own', 12982),\n ('nearby', 12972),\n ('drinks', 12955),\n ('returned', 12951),\n ('cold', 12950),\n ('lounge', 12936),\n ('booking', 12908),\n ('dubai', 12840),\n ('rather', 12803),\n ('busy', 12792),\n ('offered', 12768),\n ('decor', 12754),\n ('expected', 12678),\n ('tiny', 12669),\n ('center', 12653),\n ('special', 12640),\n ('her', 12526),\n ('english', 12517),\n ('person', 12359),\n ('windows', 12358),\n ('read', 12328),\n ('years', 12300),\n ('elevator', 12209),\n ('ready', 12191),\n ('town', 12093),\n ('card', 12032),\n ('holiday', 12010),\n ('website', 11992),\n ('arrival', 11976),\n ('fresh', 11938),\n ('francisco', 11925),\n ('reasonable', 11911),\n ('stop', 11902),\n ('ll', 11871),\n ('tower', 11867),\n ('hear', 11831),\n ('hilton', 11823),\n ('facilities', 11816),\n ('absolutely', 11777),\n ('decided', 11763),\n ('let', 11696),\n ('average', 11677),\n ('either', 11649),\n ('including', 11551),\n ('fact', 11536),\n ('views', 11510),\n ('leave', 11484),\n ('walked', 11394),\n ('upon', 11370),\n ('least', 11365),\n ('kids', 11336),\n ('shops', 11296),\n ('friends', 11286),\n ('yes', 11285),\n ('someone', 11250),\n ('dirty', 11244),\n ('budget', 11151),\n ('almost', 11139),\n ('wall', 11111),\n ('half', 11054),\n ('bathrooms', 11051),\n ('everyone', 11043),\n ('prices', 11033),\n ('complimentary', 10985),\n ('due', 10965),\n ('does', 10954),\n ('grand', 10895),\n ('later', 10889),\n ('certainly', 10881),\n ('provided', 10877),\n ('disappointed', 10826),\n ('table', 10810),\n ('between', 10789),\n ('phone', 10775),\n ('smoking', 10734),\n ('continental', 10703),\n ('wine', 10638),\n ('non', 10607),\n ('whole', 10521),\n ('offer', 10461),\n ('upgraded', 10451),\n ('spend', 10445),\n ('love', 10431),\n ('property', 10339),\n ('quick', 10312),\n ('amenities', 10307),\n ('might', 10288),\n ('light', 10259),\n ('wouldn', 10207),\n ('his', 10199),\n ('basic', 10182),\n ('housekeeping', 10153),\n ('toilet', 10105),\n ('single', 10094),\n ('kitchen', 10056),\n ('others', 10055),\n ('above', 9910),\n ('worked', 9894),\n ('real', 9845),\n ('tub', 9834),\n ('warm', 9834),\n ('why', 9798),\n ('kept', 9768),\n ('style', 9722),\n ('mins', 9696),\n ('show', 9691),\n ('site', 9654),\n ('cab', 9652),\n ('kind', 9614),\n ('flat', 9555),\n ('tried', 9548),\n ('didnt', 9532),\n ('poor', 9524),\n ('fun', 9482),\n ('union', 9413),\n ('working', 9386),\n ('under', 9376),\n ('areas', 9366),\n ('needs', 9366),\n ('upgrade', 9358),\n ('level', 9340),\n ('reservation', 9328),\n ('bags', 9307),\n ('fridge', 9271),\n ('guest', 9249),\n ('ny', 9132),\n ('ate', 9117),\n ('checking', 9112),\n ('keep', 9107),\n ('liked', 9106),\n ('done', 9077),\n ('fruit', 9043),\n ('fabulous', 9031),\n ('elevators', 9003),\n ('comfy', 8989),\n ('drink', 8936),\n ('recently', 8924),\n ('enjoy', 8919),\n ('anywhere', 8903),\n ('five', 8901),\n ('train', 8888),\n ('saw', 8866),\n ('middle', 8852),\n ('change', 8833),\n ('decorated', 8826),\n ('making', 8797),\n ('pillows', 8783),\n ('screen', 8776),\n ('point', 8764),\n ('beach', 8761),\n ('adequate', 8712),\n ('worst', 8704),\n ('centre', 8679),\n ('surprised', 8668),\n ('house', 8638),\n ('mini', 8638),\n ('dont', 8598),\n ('cool', 8581),\n ('number', 8562),\n ('efficient', 8533),\n ('luxury', 8518),\n ('priced', 8482),\n ('world', 8457),\n ('walls', 8430),\n ('requested', 8358),\n ('maybe', 8352),\n ('order', 8341),\n ('reading', 8341),\n ('tour', 8270),\n ('floors', 8245),\n ('dining', 8224),\n ('recommended', 8137),\n ('along', 8132),\n ('queen', 8125),\n ('seen', 8092),\n ('standards', 8085),\n ('run', 8061),\n ('waiting', 8046),\n ('instead', 8028),\n ('finally', 8004),\n ('las', 7988),\n ('polite', 7974),\n ('rude', 7963),\n ('coming', 7960),\n ('spa', 7954),\n ('store', 7943),\n ('rest', 7905),\n ('served', 7897),\n ('impressed', 7884),\n ('start', 7877),\n ('seem', 7859),\n ('flight', 7835),\n ('previous', 7802),\n ('set', 7794),\n ('children', 7783),\n ('local', 7779),\n ('major', 7733),\n ('yet', 7719),\n ('review', 7705),\n ('course', 7695),\n ('turn', 7686),\n ('loud', 7667),\n ('dark', 7664),\n ('friend', 7663),\n ('request', 7661),\n ('ride', 7633),\n ('heard', 7601),\n ('cable', 7592),\n ('mind', 7586),\n ('super', 7585),\n ('neighborhood', 7573),\n ('received', 7565),\n ('furniture', 7556),\n ('underground', 7554),\n ('customer', 7487),\n ('cafe', 7485),\n ('him', 7459),\n ('care', 7445),\n ('inside', 7438),\n ('cleaned', 7435),\n ('gym', 7433),\n ('touch', 7423),\n ('smell', 7417),\n ('sized', 7412),\n ('cannot', 7376),\n ('pleased', 7359),\n ('complaint', 7349),\n ('sink', 7344),\n ('manhattan', 7340),\n ('traffic', 7318),\n ('already', 7304),\n ('past', 7296),\n ('moved', 7265),\n ('fairly', 7261),\n ('construction', 7256),\n ('nicely', 7236),\n ('directly', 7223),\n ('trying', 7222),\n ('believe', 7210),\n ('attractions', 7209),\n ('key', 7200),\n ('valet', 7199),\n ('doors', 7194),\n ('rates', 7162),\n ('bars', 7159),\n ('public', 7156),\n ('twice', 7155),\n ('name', 7154),\n ('metro', 7150),\n ('issue', 7146),\n ('charged', 7138),\n ('state', 7131),\n ('superb', 7131),\n ('turned', 7124),\n ('chose', 7114),\n ('suites', 7096),\n ('seems', 7067),\n ('bring', 7067),\n ('shuttle', 7051),\n ('carpet', 7046),\n ('terrible', 7032),\n ('somewhere', 7015),\n ('garden', 7004),\n ('nd', 6996),\n ('everywhere', 6993),\n ('tired', 6993),\n ('court', 6972),\n ('living', 6968),\n ('west', 6934),\n ('despite', 6926),\n ('isn', 6916),\n ('definately', 6909),\n ('negative', 6899),\n ('wrong', 6896),\n ('using', 6892),\n ('low', 6889),\n ('entire', 6887),\n ('closet', 6885),\n ('marriott', 6878),\n ('tourist', 6862),\n ('selection', 6824),\n ('executive', 6823),\n ('sheets', 6811),\n ('min', 6805),\n ('afternoon', 6801),\n ('anyway', 6792),\n ('meal', 6748),\n ('rd', 6746),\n ('easily', 6727),\n ('resort', 6723),\n ('tell', 6714),\n ('bill', 6691),\n ('awesome', 6677),\n ('wharf', 6655),\n ('slow', 6631),\n ('entrance', 6600),\n ('separate', 6599),\n ('credit', 6597),\n ('usually', 6587),\n ('paying', 6578),\n ('move', 6575),\n ('won', 6536),\n ('larger', 6513),\n ('conditioning', 6513),\n ('avoid', 6504),\n ('district', 6499),\n ('daughter', 6487),\n ('glass', 6473),\n ('smaller', 6433),\n ('quickly', 6416),\n ('shop', 6411),\n ('welcome', 6393),\n ('except', 6363),\n ('avenue', 6358),\n ('palace', 6324),\n ('head', 6313),\n ('atmosphere', 6307),\n ('courteous', 6301),\n ('ideal', 6297),\n ('class', 6291),\n ('makes', 6268),\n ('complaints', 6252),\n ('mentioned', 6240),\n ('note', 6228),\n ('closed', 6224),\n ('myself', 6223),\n ('unless', 6192),\n ('ended', 6185),\n ('immediately', 6175),\n ('taking', 6167),\n ('river', 6159),\n ('opened', 6141),\n ('brought', 6137),\n ('appointed', 6114),\n ('south', 6087),\n ('simply', 6086),\n ('choose', 6067),\n ('fast', 6061),\n ('slept', 6059),\n ('okay', 6039),\n ('weren', 6019),\n ('cheaper', 6017),\n ('tip', 6002),\n ('daily', 5998),\n ('points', 5950),\n ('throughout', 5942),\n ('menu', 5939),\n ('changed', 5918),\n ('doesn', 5916),\n ('professional', 5916),\n ('wireless', 5883),\n ('young', 5872),\n ('toiletries', 5864),\n ('deluxe', 5863),\n ('heart', 5851),\n ('birthday', 5847),\n ('beat', 5841),\n ('lift', 5839),\n ('north', 5835),\n ('twin', 5832),\n ('group', 5825),\n ('knew', 5819),\n ('boutique', 5809),\n ('reason', 5808),\n ('sf', 5800),\n ('toast', 5795),\n ('pounds', 5785),\n ('system', 5778),\n ('lunch', 5772),\n ('reasonably', 5770),\n ('attentive', 5769),\n ('security', 5746),\n ('otherwise', 5743),\n ('looks', 5738),\n ('facing', 5729),\n ('management', 5712),\n ('downstairs', 5693),\n ('mall', 5689),\n ('soon', 5684),\n ('behind', 5683),\n ('taken', 5672),\n ('expectations', 5672),\n ('juice', 5659),\n ('ice', 5609),\n ('perfectly', 5605),\n ('hall', 5598),\n ('smoke', 5590),\n ('via', 5586),\n ('guess', 5577),\n ('music', 5577),\n ('considering', 5574),\n ('renovated', 5572),\n ('eggs', 5497),\n ('market', 5482),\n ('party', 5480),\n ('bother', 5478),\n ('met', 5471),\n ('member', 5468),\n ('compared', 5464),\n ('slightly', 5448),\n ('based', 5441),\n ('unfortunately', 5436),\n ('stairs', 5434),\n ('sofa', 5428),\n ('type', 5424),\n ('please', 5420),\n ('particularly', 5410),\n ('complain', 5400),\n ('often', 5398),\n ('watch', 5386),\n ('surprise', 5342),\n ('priceline', 5340),\n ('ave', 5306),\n ('empire', 5303),\n ('completely', 5301),\n ('sit', 5293),\n ('bottle', 5275),\n ('sitting', 5261),\n ('pricey', 5245),\n ('fault', 5243),\n ('machine', 5234),\n ('horrible', 5234),\n ('reservations', 5228),\n ('man', 5226),\n ('cleaning', 5204),\n ('elsewhere', 5202),\n ('apartment', 5200),\n ('break', 5197),\n ('seeing', 5176),\n ('theatre', 5162),\n ('nicer', 5154),\n ('visiting', 5151),\n ('buy', 5144),\n ('receptionist', 5142),\n ('saturday', 5141),\n ('bigger', 5136),\n ('outstanding', 5105),\n ('oh', 5100),\n ('items', 5074),\n ('dated', 5061),\n ('case', 5058),\n ('usual', 5050),\n ('delicious', 5045),\n ('spotless', 5035),\n ('vacation', 5031),\n ('marble', 5028),\n ('july', 5005),\n ('pick', 4992),\n ('plaza', 4983),\n ('higher', 4982),\n ('red', 4964),\n ('plan', 4959),\n ('possible', 4949),\n ('package', 4947),\n ('broken', 4942),\n ('hand', 4941),\n ('lines', 4938),\n ('comfort', 4936),\n ('east', 4933),\n ('options', 4925),\n ('spot', 4925),\n ('luxurious', 4922),\n ('third', 4914),\n ('leaving', 4907),\n ('situated', 4901),\n ('guy', 4898),\n ('pressure', 4895),\n ('option', 4888),\n ('helped', 4885),\n ('stuff', 4881),\n ('live', 4872),\n ('bay', 4868),\n ('chairs', 4862),\n ('broadway', 4861),\n ('chair', 4856),\n ('sightseeing', 4854),\n ('positive', 4852),\n ('expecting', 4851),\n ('below', 4851),\n ('online', 4832),\n ('lack', 4831),\n ('museum', 4830),\n ('services', 4816),\n ('beijing', 4788),\n ('true', 4788),\n ('handy', 4787),\n ('pleasantly', 4782),\n ('tickets', 4782),\n ('hair', 4782),\n ('com', 4777),\n ('welcoming', 4775),\n ('literally', 4763),\n ('bridge', 4760),\n ('sleeping', 4759),\n ('greeted', 4754),\n ('conference', 4754),\n ('doing', 4750),\n ('exactly', 4748),\n ('relaxing', 4746),\n ('chinese', 4745),\n ('overlooking', 4741),\n ('issues', 4731),\n ('general', 4728),\n ('older', 4727),\n ('awful', 4720),\n ('lower', 4710),\n ('base', 4710),\n ('sunday', 4700),\n ('victoria', 4698),\n ('job', 4697),\n ('wish', 4690),\n ('white', 4677),\n ('heat', 4665),\n ('sent', 4662),\n ('difficult', 4662),\n ('kensington', 4659),\n ('truly', 4651),\n ('round', 4650),\n ('offers', 4650),\n ('directions', 4646),\n ('pass', 4635),\n ('mile', 4635),\n ('fan', 4609),\n ('understand', 4578),\n ('perhaps', 4577),\n ('ago', 4567),\n ('soft', 4565),\n ('ground', 4562),\n ('thin', 4558),\n ('opposite', 4556),\n ('hyatt', 4555),\n ('typical', 4550),\n ('travelling', 4542),\n ('mention', 4535),\n ('brilliant', 4533),\n ('worn', 4532),\n ('sign', 4530),\n ('stops', 4526),\n ('private', 4521),\n ('noticed', 4516),\n ('starbucks', 4513),\n ('provide', 4508),\n ('microwave', 4506),\n ('totally', 4498),\n ('cheese', 4489),\n ('longer', 4458),\n ('mid', 4457),\n ('hyde', 4456),\n ('ritz', 4455),\n ('eating', 4451),\n ('computer', 4441),\n ('paper', 4440),\n ('stations', 4437),\n ('consider', 4435),\n ('crowded', 4427),\n ('ordered', 4422),\n ('channels', 4417),\n ('sound', 4413),\n ('whilst', 4412),\n ('obviously', 4401),\n ('speak', 4391),\n ('weeks', 4390),\n ('none', 4382),\n ...]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_frequencies.items(), reverse=True, key=lambda item: item[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "131.0"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(seq_lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "MAX_SEQ_LEN = int(np.mean(seq_lengths) + np.std(seq_lengths))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE=150053, MAX_SEQ_LEN=306\n"
     ]
    }
   ],
   "source": [
    "print(f'{VOCAB_SIZE=}, {MAX_SEQ_LEN=}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "text_ds = tf.data.TextLineDataset(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we will vectorize the vocabulary using a `tf.keras.layers.TextVectorization` layer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE + 2,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQ_LEN,\n",
    "    vocabulary=list(vocab))\n",
    "\n",
    "# vectorize_layer.adapt(text_ds.batch(1024))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the inverse vocabulary to look it up later:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'rattan', 'restrikted', 'thh', 'confernce', 'immenties', 'opining', 'expolre', 'handouts', 'effcient', 'ȡh', 'designhotel', 'pulses', 'mangaged', 'themuseums', 'rtas', 'surveys', 'эb', 'pluspoints']\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'rattan', 'restrikted', 'thh', 'confernce', 'immenties', 'opining', 'expolre', 'handouts', 'effcient', 'ȡh', 'designhotel', 'pulses', 'mangaged', 'themuseums', 'rtas', 'surveys', 'эb', 'pluspoints', 'sanctum', 'picad', 'unpleasent', 'zvbqc', 'asumin', 'pillowinternet', 'othertimes', 'citadines', 'banderas', 'amenitiesyour', 'couponsreturned', 'upholstery', 'hotelsin', 'practice', 'mountaineering', 'anisha', 'showerfood', 'wouldnt', 'facilites', 'solicitation', 'semblance', 'artsey', 'horned', 'cuising', 'morshed', 'fouton', 'friar', 'torte', 'busseness', 'klahani', 'roomswill', 'timeyou', 'survellanced', 'utube', 'barder', 'materialised', 'themselvesc', 'shubert', 'havanna', 'trimming', 'heehee', 'consiidered', 'convivia', 'forcefull', 'montrachet', 'damn', 'prague', 'reportst', 'supplying', 'prepeared', 'accured', 'rathna', 'cashout', 'gbk', 'replacemnet', 'presentazione', 'hoitey', 'burn', 'outnumbered', 'urbanes', 'nusband', 'conveninces', 'islamaphobic', 'degraded', 'mutual', 'sympathtically', 'summarythink', 'onatario', 'cancel', 'hoursbreakfast', 'twosome', 'cleanedtheir', 'nyt', 'barbreakfast', 'isjust', 'dancy', 'profssional', 'legendry', 'conchiglia', 'hogan', 'smother', 'prupose', 'aregent', 'freshy', 'reasons', 'knuckle', 'nougahide', 'coronas', 'frites', 'hauser', 'ҳs', 'transparent', 'absoluetely', 'godzilla', 'lapperts', 'instalment', 'squeaky', 'interessa', 'marnier', 'brisque', 'belligio', 'ĳerd', 'passges', 'demolishion', 'tabletv', 'climat', 'clangy', 'syq', 'saq', 'bathhrooms', 'insuperable', 'consolidated', 'speacialty', 'hangzou', 'bookedthe', 'plateful', 'muityanu', 'componets', 'deactivated', 'alamed', 'ibryibhm', 'straightening', 'innenstadt', 'townhome', 'gelert', 'itselfis', 'northwick', 'incarsaration', 'giggles', 'thankness', 'roadearls', 'althougn', 'presse', 'aspettare', 'highchair', 'minefield', 'missile', 'januarywe', 'reviues', 'satin', 'epiphany', 'bkt', 'eyeshadow', 'qcmd', 'upw', 'almanacs', 'konstantino', 'oxfood', 'intensified', 'iced', 'peopleneg', 'habitue', 'relaize', 'punishment', 'rougly', 'outsaid', 'auth', 'fabreeze', 'chlorhine', 'greying', 'arriver', 'opposit', 'unsorted', 'unblocking', 'spraying', 'attarations', 'heartbreak', 'soybean', 'hopins', 'forgottenthe', 'carcar', 'minuteswhen', 'holdups', 'mcafee', 'straightning', 'scruffy', 'crashin', 'uppgraded', 'priviliege', 'againon']\n"
     ]
    }
   ],
   "source": [
    "print(inverse_vocab[:200])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Vectorize the data in text_ds.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtain Sequences from the Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255404\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100025  48398  18320 136594  58478  84900 137733 133356  97218  22238\n",
      "   6376 136594  55223  31363  67270  47090   6376 114927 148479 118487\n",
      " 133017 111882  69496 128181 143719  15102  31628  84900  37303  95790\n",
      " 141536  18336  53909  14182  31628  84900 126162  90216   9159  45535\n",
      "  14540 139515  97717  94528   5598 128181 136594  18336 105383   9720\n",
      "  55306  90309 128181 124584  69496 128181  29792 117063  72110  54527\n",
      " 141536  18336 105383  60048  53909  54703 133718 128181 142657  58908\n",
      " 143167  46530  90309 106801  16798 100636  69496 133017  41419  30181\n",
      " 105469   9348 140061  90216  90277 146070  90216  38909 126585 128181\n",
      " 100797 118153  47090 139515  48526 144154  50673  19851  18336  68127\n",
      " 121355 113728 149258 130207  22238 141536  18336  49787 125682  69496\n",
      " 136831 108469  22238 113728  20566  41419  60025  48398   9040  33146\n",
      " 134215  18336  48398  53909  48285  45535   9348  85913  53909  49854\n",
      " 106462  22238 105499 134215  53909  56553 135580  36807  73365  93235\n",
      "  69496  64674  19621 111882  39292  95022  92193 128181  58478 114927\n",
      "  84900 110481 141536 114927   5598 128181 147396   7377  56643  53909\n",
      "  56553  80441  42726  90216 100248 143719  41419  21102  56553   9348\n",
      "  84900 127959 143579  27775  90216  49181 128181  60073 129728  22238\n",
      " 114624  80441  56553   8306 134439 101253 122489  90216 139515 111882\n",
      " 131091  22238 128181 136594  47352  18336  64554 101826  53909  45535\n",
      "  18336  92559  53805  69496  38542  45535   9348 125682  69496  92072\n",
      "  90216 129635  22238 128181  51794  54527  47090 117368  47090   7688\n",
      " 129423  45535 114927 137637 121355  64815   7688  53909 105885  54527\n",
      "  41541 103728 114144  22238   6376 136594  94717  41419  49787  21102\n",
      "  31628  84900   9840  90216  34745  90216   5512 114624  47090 141536\n",
      "  47925 100248  44546  68706 128181  58478 114927 101253  21102  56553\n",
      "   9840  90216  73072  70229  69496  94710  47090  45535 114927  40011\n",
      "  94710  48091  38712  73341  59409  59330 123615 128181 136594  53909\n",
      "  45535   9348  90276  69496 113862  39741 144767  64474 113692 146070\n",
      "  22706  53549 121592      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0] => ['oct', 'nice', 'trendy', 'hotel', 'location', 'not', 'too', 'bad', 'stayed', 'in', 'this', 'hotel', 'for', 'one', 'night', 'as', 'this', 'is', 'fairly', 'new', 'place', 'some', 'of', 'the', 'taxi', 'drivers', 'did', 'not', 'know', 'where', 'it', 'was', 'and', 'or', 'did', 'not', 'want', 'to', 'drive', 'there', 'once', 'have', 'eventually', 'arrived', 'at', 'the', 'hotel', 'was', 'very', 'pleasantly', 'surprised', 'with', 'the', 'decor', 'of', 'the', 'lobby', 'ground', 'floor', 'area', 'it', 'was', 'very', 'stylish', 'and', 'modern', 'found', 'the', 'reception', 'staff', 'geeting', 'me', 'with', 'aloha', 'bit', 'out', 'of', 'place', 'but', 'guess', 'they', 'are', 'briefed', 'to', 'say', 'that', 'to', 'keep', 'up', 'the', 'coroporate', 'image', 'as', 'have', 'starwood', 'preferred', 'guest', 'member', 'was', 'given', 'small', 'gift', 'upon', 'check', 'in', 'it', 'was', 'only', 'couple', 'of', 'fridge', 'magnets', 'in', 'gift', 'box', 'but', 'nevertheless', 'nice', 'gesture', 'my', 'room', 'was', 'nice', 'and', 'roomy', 'there', 'are', 'tea', 'and', 'coffee', 'facilities', 'in', 'each', 'room', 'and', 'you', 'get', 'two', 'complimentary', 'bottles', 'of', 'water', 'plus', 'some', 'toiletries', 'by', 'bliss', 'the', 'location', 'is', 'not', 'great', 'it', 'is', 'at', 'the', 'last', 'metro', 'stop', 'and', 'you', 'then', 'need', 'to', 'take', 'taxi', 'but', 'if', 'you', 'are', 'not', 'planning', 'on', 'going', 'to', 'see', 'the', 'historic', 'sites', 'in', 'beijing', 'then', 'you', 'will', 'be', 'ok', 'chose', 'to', 'have', 'some', 'breakfast', 'in', 'the', 'hotel', 'which', 'was', 'really', 'tasty', 'and', 'there', 'was', 'good', 'selection', 'of', 'dishes', 'there', 'are', 'couple', 'of', 'computers', 'to', 'use', 'in', 'the', 'communal', 'area', 'as', 'well', 'as', 'pool', 'table', 'there', 'is', 'also', 'small', 'swimming', 'pool', 'and', 'gym', 'area', 'would', 'definitely', 'stay', 'in', 'this', 'hotel', 'again', 'but', 'only', 'if', 'did', 'not', 'plan', 'to', 'travel', 'to', 'central', 'beijing', 'as', 'it', 'can', 'take', 'long', 'time', 'the', 'location', 'is', 'ok', 'if', 'you', 'plan', 'to', 'do', 'lot', 'of', 'shopping', 'as', 'there', 'is', 'big', 'shopping', 'centre', 'just', 'few', 'minutes', 'away', 'from', 'the', 'hotel', 'and', 'there', 'are', 'plenty', 'of', 'eating', 'options', 'around', 'including', 'restaurants', 'that', 'serve', 'dog', 'meat', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[ 25400 110481 131622 136594  97218  36807 137732   5598 100001 143579\n",
      " 128181   3005  20602  98760  90216  87386 128181 136594  18336 105383\n",
      "  54703  53909  27649 128181 134215  18336  17555  53909 136959  63182\n",
      "  43921  77874  47090  71442  47090  25658  85922 136906  22238  87386\n",
      " 128181  58908  18336 105383  33609  53909   4428 100636  69496 128181\n",
      " 140961  90216   4999  33146  11160  42726  64474  27775  90216   3406\n",
      "  27814 128181  12977  90216 125220  87386  49513  96542  50990  55223\n",
      "  46530 128181 135527 131091  18336 108595  70822  90216 105671  58665\n",
      " 117727 128181  73576  68574 103414  80609 143579  35807  55223  92679\n",
      "  53909 103414  92559  53805  69496 111201  59010  64474 128201  97781\n",
      " 115330  13459 132954   5164 128181 105885  18336 121355 103414  53805\n",
      "  69496  11157  87543  53909  31363  89155   8851  45535  18336  86925\n",
      " 118487  70043 130581  26255  90309 103971  22238  73576  17739  47352\n",
      "  14830 105383  92559 128181  58478 114927  16798 100636  69496 128181\n",
      " 140961  90216 128181   5512  89422  69496 114624  41419 141536 114927\n",
      " 146973  42917  55223  33146 104228  47090  42726  90216 134439  22238\n",
      " 128181 124716  45128 132212  80691  29937  45535  14830  71070  29144\n",
      "  90216 146973 134215  64829 100001  26301  91336  69496  84900   8244\n",
      "  94088  29144 128181  92278  35128  57667 114927 148594 145705 136594\n",
      "  22238  33146 138793  95790  10451 111288   6376 123615   6183  90309\n",
      "   3184 103001 134215  41419  47090  71442  47090  68065  55223 128181\n",
      " 130865 100001 114927 110481 133017      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0] => ['sep', 'great', 'budget', 'hotel', 'stayed', 'two', 'nights', 'at', 'aloft', 'on', 'the', 'most', 'recent', 'trip', 'to', 'china', 'the', 'hotel', 'was', 'very', 'modern', 'and', 'clean', 'the', 'room', 'was', 'spotless', 'and', 'comfortable', 'king', 'sized', 'bed', 'as', 'far', 'as', 'soft', 'beds', 'go', 'in', 'china', 'the', 'staff', 'was', 'very', 'punctual', 'and', 'went', 'out', 'of', 'the', 'way', 'to', 'help', 'my', 'every', 'need', 'including', 'going', 'to', 'store', 'across', 'the', 'street', 'to', 'purchase', 'china', 'mobile', 'sim', 'card', 'for', 'me', 'the', 'buffet', 'breakfast', 'was', 'okay', 'nothing', 'to', 'write', 'home', 'about', 'the', 'lcd', 'screen', 'had', 'movies', 'on', 'demand', 'for', 'rmb', 'and', 'had', 'good', 'selection', 'of', 'western', 'channels', 'including', 'hbo', 'cnn', 'bbc', 'star', 'world', 'etc', 'the', 'gym', 'was', 'small', 'had', 'selection', 'of', 'basic', 'weights', 'and', 'one', 'cable', 'machine', 'there', 'was', 'however', 'new', 'technogym', 'cardio', 'machines', 'with', 'built', 'in', 'lcd', 'tvs', 'which', 'were', 'very', 'good', 'the', 'location', 'is', 'bit', 'out', 'of', 'the', 'way', 'to', 'the', 'central', 'areas', 'of', 'beijing', 'but', 'it', 'is', 'better', 'suited', 'for', 'my', 'needs', 'as', 'need', 'to', 'be', 'in', 'the', 'haidian', 'district', 'being', 'spg', 'platinum', 'there', 'were', 'no', 'upgrades', 'to', 'better', 'room', 'because', 'aloft', 'has', 'policy', 'of', 'not', 'doing', 'any', 'upgrades', 'the', 'sheraton', 'next', 'door', 'is', 'much', 'nicer', 'hotel', 'in', 'my', 'opinion', 'where', 'am', 'writing', 'this', 'from', 'now', 'with', 'an', 'upgraded', 'room', 'but', 'as', 'far', 'as', 'bang', 'for', 'the', 'buck', 'aloft', 'is', 'great', 'place', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[ 34677 109995 113401  58478  84900  40011  66489  71756  97218   5598\n",
      " 128181 100001 114624 124716  55223 137732 123615  21511 125696  45535\n",
      "   9348 139128  69496 146583 146070  24303 117727 128181  58478 132212\n",
      "  66489  41419  71756  69171   6376  50496  69496  68706  53909 133718\n",
      " 146070 141536  64554  42076   3184 145438 128181 123760  71756  48497\n",
      "  22238 143719  18336 117727  59409  71756 146361  65021  32465  21232\n",
      "  92679  55223 143719 101949  47352 114927 117727  66682  53909 146070\n",
      "  18336  90216 128181    984  79928  68127  45535   9348  22238 107470\n",
      "  52509 141536  18336  71070  40011 148078   5598 137862  47090  55223\n",
      " 128181 115863 105469  14830  27649 128181  85922 136959 128181  64742\n",
      " 145115  27132  60870  53909 141536  18336  31363  69496 128181  73341\n",
      "  52575  71756 133718  22238 114624 146070  41541  39249   2780  53909\n",
      "  63072  71756  65021 117727  66682  45055  67270 146070   3184  26838\n",
      "  57396 141536  84900 110323  90216 134439  13459 136594  13650  56553\n",
      "  47925 136906  22238  32709 146070  71756 133718 128181 142657  58908\n",
      " 104268 105383  26795  53909  13044 105469  85044 128181 146965  22238\n",
      " 128181 132954  41419 141536  42076  13131   5598 137862 128181 136594\n",
      " 108921  74058   3184 124524  90216 110010  90309  21916  73341 110147\n",
      "  53909  18336 137076  26795  53909  98932  40670 131091 135527  18336\n",
      "  28418  92559  53909 115732 130308  45535   9348 127740  69496  92559\n",
      " 113692  22238 128181 130925   2923  92278  35128  57667  13650  45535\n",
      "  14830 139128  69496  39741  45535 114927  46586 128492 117727  28189\n",
      "  59330 146070  26301  74291  33393  39741  47090 117368 128181  49787\n",
      " 145438  71756 114983  91598  18336  73341 143719  15102  83506  90216\n",
      " 100248  21916  90216 128181  61384  86218  64829  30181 105469  71269\n",
      " 141536  42076  71442  28585 128181  16218 112199 114927  92679  41419\n",
      " 128181  58908   5598 128181 130925   2923  92278  47352 114927 143579\n",
      "  80328 121453  21232 128181  35560  12977  55223 100001  14830  28418\n",
      "  26795  22238 105012 126754  55223  21916  21102 105469  81229 125453\n",
      "  45535  71756  41541 103728 114144  45535  94717  53909 118413 141536\n",
      "  90216 107470  79109  55223 115591 109995] => ['aug', 'excellent', 'value', 'location', 'not', 'big', 'problem', 'we', 'stayed', 'at', 'the', 'aloft', 'beijing', 'haidian', 'for', 'nights', 'from', 'july', 'nd', 'there', 'are', 'lots', 'of', 'reviews', 'that', 'talk', 'about', 'the', 'location', 'being', 'problem', 'but', 'we', 'knew', 'this', 'ahead', 'of', 'time', 'and', 'found', 'that', 'it', 'really', 'wasn', 'an', 'issue', 'the', 'longest', 'we', 'spent', 'in', 'taxi', 'was', 'about', 'minutes', 'we', 'never', 'paid', 'more', 'than', 'rmb', 'for', 'taxi', 'ride', 'which', 'is', 'about', 'cdn', 'and', 'that', 'was', 'to', 'the', 'forbidden', 'city', 'given', 'there', 'are', 'in', 'our', 'family', 'it', 'was', 'no', 'big', 'deal', 'at', 'all', 'as', 'for', 'the', 'rooms', 'they', 'were', 'clean', 'the', 'beds', 'comfortable', 'the', 'wireless', 'internet', 'connection', 'reliable', 'and', 'it', 'was', 'one', 'of', 'the', 'few', 'hotels', 'we', 'found', 'in', 'beijing', 'that', 'would', 'accomodate', 'adults', 'and', 'children', 'we', 'paid', 'about', 'cdn', 'per', 'night', 'that', 'an', 'amazing', 'price', 'it', 'not', 'meant', 'to', 'be', 'star', 'hotel', 'so', 'you', 'can', 'go', 'in', 'expecting', 'that', 'we', 'found', 'the', 'reception', 'staff', 'generally', 'very', 'helpful', 'and', 'friendly', 'they', 'aren', 'the', 'fastest', 'in', 'the', 'world', 'but', 'it', 'wasn', 'unreasonable', 'at', 'all', 'the', 'hotel', 'manager', 'made', 'an', 'effort', 'to', 'speak', 'with', 'us', 'few', 'times', 'and', 'was', 'extremely', 'helpful', 'and', 'welcoming', 'their', 'breakfast', 'buffet', 'was', 'quite', 'good', 'and', 'reasonably', 'priced', 'there', 'are', 'number', 'of', 'good', 'restaurants', 'in', 'the', 'four', 'points', 'sheraton', 'next', 'door', 'so', 'there', 'were', 'lots', 'of', 'options', 'there', 'is', 'massive', 'mall', 'about', 'block', 'away', 'that', 'has', 'other', 'dining', 'options', 'as', 'well', 'the', 'only', 'issue', 'we', 'ran', 'into', 'was', 'few', 'taxi', 'drivers', 'refusing', 'to', 'take', 'us', 'to', 'the', 'summer', 'palace', 'because', 'guess', 'they', 'felt', 'it', 'wasn', 'far', 'enough', 'the', 'minimum', 'rate', 'is', 'rmb', 'but', 'the', 'staff', 'at', 'the', 'four', 'points', 'sheraton', 'which', 'is', 'on', 'busier', 'road', 'than', 'the', 'side', 'street', 'for', 'aloft', 'were', 'quite', 'helpful', 'in', 'finding', 'taxis', 'for', 'us', 'if', 'they', 'weren', 'already', 'there', 'we', 'would', 'definitely', 'stay', 'there', 'again', 'and', 'recommend', 'it', 'to', 'our', 'friends', 'for', 'its', 'excellent']\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences[:3]:\n",
    "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate training examples from sequences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(VOCAB_SIZE)\n",
    "sampling_table[130000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with a positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "\n",
    "      # context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "\n",
    "      context_class = context_word.reshape(1, 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=SEED,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "      context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "      # label = tf.constant([1] + [0] * num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "    labels += [tf.constant([1] + [0] * num_ns, dtype=\"int64\")] * len(positive_skip_grams)\n",
    "\n",
    "  return targets, contexts, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the data is too big (RAM wise) we will generate training data in chunks:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train_data_path = Path('train_data')\n",
    "if not train_data_path.exists():\n",
    "    train_data_path.mkdir()\n",
    "\n",
    "num_chunks = 100\n",
    "step = len(sequences) // num_chunks\n",
    "for i in range(num_chunks):\n",
    "    targets_path = train_data_path / f'targets{i}.npy'\n",
    "    contexts_path = train_data_path / f'contexts{i}.npy'\n",
    "    labels_path = train_data_path / f'labels{i}.npy'\n",
    "\n",
    "    if targets_path.exists() and contexts_path.exists() and labels_path.exists():\n",
    "        continue\n",
    "\n",
    "    print(f'{i=}')\n",
    "\n",
    "    targets, contexts, labels = generate_training_data(\n",
    "        sequences=sequences[i * step:(i + 1) * step],\n",
    "        window_size=WINDOW_SIZE,\n",
    "        num_ns=NUM_NS,\n",
    "        vocab_size=VOCAB_SIZE + 2)\n",
    "\n",
    "    targets = np.array(targets)\n",
    "    contexts = np.array(contexts)[:,:,0]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print('\\n')\n",
    "    print(f\"targets.shape: {targets.shape}\")\n",
    "    print(f\"contexts.shape: {contexts.shape}\")\n",
    "    print(f\"labels.shape: {labels.shape}\")\n",
    "\n",
    "    np.save(targets_path, targets)\n",
    "    np.save(contexts_path, contexts)\n",
    "    np.save(labels_path, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we have the training data in chunks. Meaning, 100 .npy files with targets, contexts and labels, each."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(5,)\n",
      "[1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.load(train_data_path / 'targets0.npy')\n",
    "b = np.load(train_data_path / 'contexts0.npy')\n",
    "c = np.load(train_data_path / 'labels0.npy')\n",
    "print(a[0].shape)\n",
    "print(b[0].shape)\n",
    "print(c[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "input_target = layers.Input(shape=())\n",
    "input_context = layers.Input(shape=(NUM_NS + 1,))\n",
    "embedding_target = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=1, name=\"w2v_embedding\")(input_target)\n",
    "embedding_context = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=NUM_NS + 1)(input_context)\n",
    "\n",
    "dotted = layers.Dot(axes=-1)([embedding_target, embedding_context])\n",
    "model = models.Model(inputs=[input_target, input_context], outputs=dotted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((a, b), c))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2138/2885 [=====================>........] - ETA: 59s - loss: 0.0136 - accuracy: 0.9958"
     ]
    }
   ],
   "source": [
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "model.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KerasTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [75]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43minput_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'KerasTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "input_target(a[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"model\" (type Functional).\n\n'numpy.int64' object has no attribute '_keras_mask'\n\nCall arguments received:\n  • inputs=('21570', 'tf.Tensor(shape=(5,), dtype=int64)')\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [74]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\orly310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\orly310\\lib\\site-packages\\keras\\engine\\functional.py:565\u001B[0m, in \u001B[0;36mFunctional._run_internal_graph\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    563\u001B[0m   masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flatten_to_reference_inputs(mask)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m input_t, mask \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(inputs, masks):\n\u001B[1;32m--> 565\u001B[0m   input_t\u001B[38;5;241m.\u001B[39m_keras_mask \u001B[38;5;241m=\u001B[39m mask\n\u001B[0;32m    567\u001B[0m \u001B[38;5;66;03m# Dictionary mapping reference tensors to computed tensors.\u001B[39;00m\n\u001B[0;32m    568\u001B[0m tensor_dict \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[1;31mAttributeError\u001B[0m: Exception encountered when calling layer \"model\" (type Functional).\n\n'numpy.int64' object has no attribute '_keras_mask'\n\nCall arguments received:\n  • inputs=('21570', 'tf.Tensor(shape=(5,), dtype=int64)')\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "model((a[0], b[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}